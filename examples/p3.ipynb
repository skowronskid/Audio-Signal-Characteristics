{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from functions.time_domain import *\n",
    "from functions.frequency_domain import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions.time_domain import *\n",
    "from functions.frequency_domain import *\n",
    "\n",
    "def preemphasis(signal, coeff=0.97, frame_rate=None, display=False):\n",
    "    preepmhasized_signal = np.append(signal[0], signal[1:] - coeff * signal[:-1])\n",
    "    if display:\n",
    "        displayhook(Audio(preepmhasized_signal, rate=frame_rate))\n",
    "    return preepmhasized_signal\n",
    "\n",
    "\n",
    "\n",
    "def get_filter_banks(n_filters=16, NFFT=512, frame_rate=None, low_freq_mel=0, high_freq_mel=None):\n",
    "    if high_freq_mel is None:\n",
    "        high_freq_mel = (2595 * np.log10(1 + (frame_rate / 2) / 700))\n",
    "    mel_points = np.linspace(low_freq_mel, high_freq_mel, n_filters + 2)  \n",
    "    hz_points = (700 * (10**(mel_points / 2595) - 1))  \n",
    "    bins = np.floor((NFFT + 1) * hz_points / frame_rate)\n",
    "\n",
    "    fbank = np.zeros((n_filters, int(np.floor(NFFT / 2 + 1))))\n",
    "    for m in range(1, n_filters + 1):\n",
    "        f_m_minus = int(bins[m - 1])   # left\n",
    "        f_m = int(bins[m])             # center\n",
    "        f_m_plus = int(bins[m + 1])    # right\n",
    "\n",
    "        for k in range(f_m_minus, f_m):\n",
    "            fbank[m - 1, k] = (k - bins[m - 1]) / (bins[m] - bins[m - 1])\n",
    "        for k in range(f_m, f_m_plus):\n",
    "            fbank[m - 1, k] = (bins[m + 1] - k) / (bins[m + 1] - bins[m])\n",
    "    return fbank\n",
    "\n",
    "def get_dct_coefficients(input_signals, M):\n",
    "    num_signals = len(input_signals)\n",
    "    dct_coefficients = np.zeros((num_signals, M))  # Initialize the array for DCT coefficients\n",
    "\n",
    "    for n in range(num_signals):\n",
    "        input_signal = input_signals[n]\n",
    "\n",
    "        for i in range(M):\n",
    "            for m in range(M):\n",
    "                dct_coefficients[n, i] += np.log(input_signal[m]) * np.cos((np.pi * i) / (2 * M) * (m - 0.5))\n",
    "\n",
    "        dct_coefficients[n] *= np.sqrt(2 / M)  # Apply the scaling factor\n",
    "\n",
    "    return dct_coefficients\n",
    "\n",
    "\n",
    "def get_energy(frame):\n",
    "    return np.sum(np.square(frame))\n",
    "\n",
    "def mfcc_pipeline(path):\n",
    "    percent_frame_size = 0.15\n",
    "    percent_hop_length = 0.5\n",
    "    audio, frame_rate, audio_time, n_samples  = read_wave(path, display=False)\n",
    "    preepmhasized_audio = preemphasis(audio, frame_rate=frame_rate, display=False)\n",
    "    frames, n_, N_ = split_to_frames(preepmhasized_audio, frame_rate, percent_frame_size=percent_frame_size, percent_hop_length=percent_hop_length, set_frame_size=256)\n",
    "    fft_frames = transform_frames_to_frequency_domain(frames, frame_rate, N_, window_type='hamming')\n",
    "    amplitude = np.abs(fft_frames)[:,:N_//2+1]\n",
    "    magnitude = amplitude**2\n",
    "    filters = get_filter_banks(n_filters=16, NFFT=256, frame_rate=frame_rate)\n",
    "    filtered_magnitude = np.dot(magnitude, filters.T)\n",
    "    mfcc = get_dct_coefficients(filtered_magnitude, filtered_magnitude.shape[1])\n",
    "    energy = np.apply_along_axis(get_energy, 1, frames)\n",
    "    \n",
    "    return mfcc, energy\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'../recordings/4_10/Znormalizowane/bapis_1.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc, energy = mfcc_pipeline(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = glob.glob(\"Znormalizowane/*.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dzwiek",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
